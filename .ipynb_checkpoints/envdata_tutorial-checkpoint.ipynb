{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Environmental Data with pandas and GeoPy\n",
    "\n",
    "**Objective**: Utilize Python libraries to clean and work through boat launch steward survey data that is predominantly categorical.\n",
    "\n",
    "**Data Source**: 2016 Boat Launch Steward Data from St. Lawrence Eastern Lake Ontario Partnership for Regional Invasive Species Management ([SLELO PRISM](https://www.sleloinvasives.org/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add packages needed\n",
    "import pandas as pd # provides interface for viewing tabular data\n",
    "import geopy as gp # works as client for accessing geocoding webservices\n",
    "from geopy.geocoders import Nominatim # free service to access OpenStreetMaps data to find locations\n",
    "from geopy.distance import great_circle # for measuring distance between points\n",
    "import numpy as np # for formatting nontype values\n",
    "import ast # for processing abstract syntax grammar of variables\n",
    "import matplotlib.pyplot as plt # for visualizing data\n",
    "import seaborn as sb # for visualizing data\n",
    "\n",
    "pd.options.display.max_columns = None # visualize all columns in the dataframe\n",
    "\n",
    "# Set the user agent, to show which browser is used for geopy, and specify Nominatim as the geolocator\n",
    "chrome_user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.92 Safari/537.36\"\n",
    "geolocator = Nominatim(timeout=10,user_agent=chrome_user_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the original survey data, and check out the data types and a preview of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bls-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Attribute Information:\n",
    "     1. Steward Name:             A,B,C,D\n",
    "     2. Boat Launch:              Cape Vincent,Henderson,Sackets Harbor,Wrights Landing\n",
    "     3. Weather Conditions:       Various (string type)\n",
    "     4. Date:                     Various (string type)\n",
    "     5. Inspection Time:          Various (string type)   \n",
    "     6. Boat Type:                Motorized=M,Kayak=K,Personal Watercraft=PWC,Sailboat=S,Canoe=C,Motorized Sailboat=M/S\n",
    "     7. Group Size:               Various (integer)\n",
    "     8. State of Registration:    Various (string types of state abbreviations)\n",
    "     9. Launch or Retrieve:       Launch=L,Retrieve=R\n",
    "    10. Prior BLS contact?:       Yes=Y,No=N\n",
    "    11. Spread Prevention Steps:  Wash Boat=WB,Remove Weeds=RW,Drain Bilge Water=DBW,Clean, Drain, Dry=CDD,\n",
    "                                  Drain Livewells=LW,Dispose of Bait Properly=DB,Drain Boat Ballast=DBB,Dries Boat=Dry\n",
    "                                  None=None,Not Recorded = NaN, \n",
    "    12. Aquatic Organisms Found?: Yes=Y,No=N\n",
    "    13. Species ID: \t          Eelgrass=EG,Elodea=EL,Curly-leaf Pondweed=CLP,Eurasian Watermilfoil=EWM,\n",
    "                                  Zebra Mussel=ZM,Native Pondweed=NP,Coontail=CT,Variable leaf Milfoil=VLM,\n",
    "                                  Unknown=UNK,Other=Other,Not Recorded=NaN\n",
    "    14. Accepted Info Materials?: Yes=Y,No=N\n",
    "    15. Last Waterbody Visited:   Various (string type)\n",
    "    16. Last Waterbody Cleaned:   Various (string type)\n",
    "    17. Next Waterbody to Visit:  Various (string type)\n",
    "    18. Next Waterbody Cleaned:   Various (string type)\n",
    "    19. Planned Travel Route:     Various (string type)\n",
    "    20. Would Use a Decontamination Station?: Yes=Y, No=N, Maybe=M, Not Recorded=NaN\n",
    "    21. Purpose:                  Recreation,Fishing,Fishing and Recreation,Not Recorded=NaN\n",
    "    22. Notes:                    Various (string type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the columns for 'Date' and 'Time' to reflect date and time data types, rather than strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(df['Date'], cache=True) \n",
    "times = pd.to_timedelta(df['Inspection Time'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = dates\n",
    "df['Inspection Time'] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend 'Spread Prevention Steps' column and 'Species ID' column into their own dataframes, then concatenate with the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df, df['Spread Prevention Steps'].str.get_dummies(sep=\",\").rename(lambda x: 'Prev_Step_' + x, axis=1)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df2, df2['Species ID'].str.get_dummies(sep=\",\").rename(lambda x: 'Species_' + x, axis=1)], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the 'Last Waterbody Cleaned' column on its delimiter ('|') in a new dataframe. Do the same for the 'Next Waterbody Cleaned' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3['Last Waterbody Cleaned'].str.split('|',n=0, expand=True)\n",
    "df4.columns = ['Prev_Loc{}'.format(x+1) for x in df4.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df3['Next Waterbody Cleaned'].str.split('|',n=0, expand=True)\n",
    "df5.columns = ['Next_Loc{}'.format(x+1) for x in df5.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to run the geocoder on the waterbodies, or closest locations, specified. We want to avoid iterating over every single row because many of the locations repeat. Therefore, we'll make two arrays of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make columns into a flattened array and get unique values from that. The argument 'K' tells to flatten in the order \n",
    "they are stored to memory.\n",
    "\"\"\"\n",
    "all_locs_prev = pd.unique(df4[['Prev_Loc1', 'Prev_Loc2','Prev_Loc3','Prev_Loc4','Prev_Loc5']].values.ravel('K'))\n",
    "all_locs_next = pd.unique(df5[['Next_Loc1', 'Next_Loc2','Next_Loc3']].values.ravel('K'))\n",
    "\n",
    "# merge these two and grab unique values\n",
    "both_locs = [next(iter(filter(None, values)), '') for values in zip(all_locs_prev, all_locs_next)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(both_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above array, we'll remove some of the erroneous entries that might throw off the geocoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_all_locs = [x for x in both_locs if str(x) not in ['nan','None','Undecided']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary for all location and their respective coordinates. We use the geocoder to get the latitude and longitudes for all values that do not equal 'None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all_locs = dict(zip(cleaned_all_locs, pd.Series(cleaned_all_locs).apply(geolocator.geocode).apply(lambda x: (x.latitude if x != None else None, x.longitude if x != None else None))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map all coordinates to their respective locations and create new columns for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Prev_Coord1'] = df4['Prev_Loc1'].map(dict_all_locs)\n",
    "df4['Prev_Coord2'] = df4['Prev_Loc2'].map(dict_all_locs)\n",
    "df4['Prev_Coord3'] = df4['Prev_Loc3'].map(dict_all_locs)\n",
    "df4['Prev_Coord4'] = df4['Prev_Loc4'].map(dict_all_locs)\n",
    "df4['Prev_Coord4'] = df4['Prev_Loc5'].map(dict_all_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['Next_Coord1'] = df5['Next_Loc1'].map(dict_all_locs)\n",
    "df5['Next_Coord2'] = df5['Next_Loc2'].map(dict_all_locs)\n",
    "df5['Next_Coord3'] = df5['Next_Loc3'].map(dict_all_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save each location dataframe as string types for later use with calculating the distance between points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.astype(str)\n",
    "df5 = df5.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column for the respective coordinates for the boat launch locations, and map that and insert the column next to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boat_launch_coords = {'Cape Vincent':'(44.125494, -76.33046406316765)', 'Henderson':'(43.8647846, -76.2018719)','Sackets Harbor':'(43.946171, -76.119093)','Wrights Landing': '(43.463814850000006, -76.51876930187919)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_boat_launch_coords = df3['Boat Launch'].map(boat_launch_coords)\n",
    "df3.insert(2, 'Boat Launch Coords', mapped_boat_launch_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the dataframes with the separate location names and coordinates with the main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df3.join(df4)\n",
    "df7 = df6.join(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved the merged dataframes to a CSV for later use, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df7.to_csv('merged_bls-data.csv', index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new rows for the distances between the boat launch and the locations from where the boaters came from, and where they intended to go next. I add rows only for the first locations mentioned for each, but the intention would be to get these values for all mentioned instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_calc1(row):\n",
    "    coordA = row['Prev_Coord1']\n",
    "    coordB = row['Boat Launch Coords']\n",
    "    try:\n",
    "        return great_circle(ast.literal_eval(coordA), ast.literal_eval(coordB)).miles\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "df7['Dist_Miles_Prev1'] = df7.apply(distance_calc1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_calc2(row):\n",
    "    coordA = row['Next_Coord1']\n",
    "    coordB = row['Boat Launch Coords']\n",
    "    try:\n",
    "        return great_circle(ast.literal_eval(coordA), ast.literal_eval(coordB)).miles\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "df7['Dist_Miles_Next1'] = df7.apply(distance_calc2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['Dist_Miles_Prev1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the spread of one of the coordinate sets, and then split into 4 quantiles for graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['Dist_Miles_Next1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['Dist_Miles_Next1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['Dist_Miles_Next1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['Quantile_Dist_Prev1'] = pd.qcut(df7['Dist_Miles_Prev1'], q=4, duplicates='drop')\n",
    "df7['Quantile_Dist_Next1'] = pd.qcut(df7['Dist_Miles_Next1'], q=4, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7['Quantile_Dist_Prev1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create graphs based on the data using matplotlib and seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countplots help easily summarize survey response categories, and we can apply our created variables such as the quantiles for travel distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = sb.countplot(x='Would Use a Decontamination Station?', data=df7, edgecolor=(0,0,0), palette='pastel')\n",
    "ax.set(xlabel=None,ylabel='Count of Responses', title='Would Boaters Use a Decontamination Station?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = sb.countplot(x='Would Use a Decontamination Station?', hue='Boat Launch', data=df7, \n",
    "                  edgecolor=(0,0,0), palette='pastel')\n",
    "ax.set(xlabel=None,ylabel='Count of Responses', title='Would Boaters Use a Decontamination Station?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = sb.countplot(x='Quantile_Dist_Prev1', hue='Would Use a Decontamination Station?', data=df7, \n",
    "                  edgecolor=(0,0,0), palette='pastel')\n",
    "ax.set(xlabel='Distance from Last Waterbody Visited (Range in Miles)', ylabel='Count of Responses', \n",
    "       title='Distance Traveled and Likelihood of Decontamination Station Use')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at distances traveled, we can specify to remove the outliers using seaborn's 'showfliers' argument. This helps accomodate the variance in minimum and maximum distances involved in travel results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at distances traveled, removing outliers\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = sb.boxplot(x='Purpose', y='Dist_Miles_Prev1', data=df7, palette='pastel',showfliers=False)\n",
    "ax.set(xlabel=None, ylabel='Distance from Last Waterbody Visited (Miles)', \n",
    "       title='Purpose of Boating Trip and Previous Travel Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = sb.boxplot(x='Purpose', y='Dist_Miles_Next1', data=df7, palette='pastel',showfliers=False)\n",
    "ax.set(xlabel=None, ylabel='Distance to Next Waterbody Visited (Miles)', \n",
    "       title='Purpose of Boating Trip and Next Planned Travel Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a datafrane with only the responses where aquatic organisms were identified, and plot the instances of each invasive species type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_found = df7.loc[df['Aquatic Organisms Found?'] == 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "fig_dims = (3, 3)\n",
    "\n",
    "ax1 = plt.subplot2grid(fig_dims, (0, 0))\n",
    "a = sb.countplot(x='Species_EWM', data=species_found, edgecolor=(0,0,0), palette='pastel')\n",
    "plt.ylim(0,400)\n",
    "a.set(xlabel=None, ylabel=None, title='Eurasian Water Milfoil')\n",
    "ax2 = plt.subplot2grid(fig_dims, (0, 1))\n",
    "b = sb.countplot(x='Species_VLM', data=species_found, edgecolor=(0,0,0), palette='pastel')\n",
    "plt.ylim(0,400)\n",
    "b.set(xlabel=None, ylabel=None, title='Variable Leaf Milfoil')\n",
    "ax3 = plt.subplot2grid(fig_dims, (0, 2))\n",
    "c = sb.countplot(x='Species_ZM', data=species_found, edgecolor=(0,0,0), palette='pastel')\n",
    "plt.ylim(0,400)\n",
    "c.set(xlabel=None, ylabel=None, title='Zebra Mussel')\n",
    "fig.suptitle('Total Observations of Invasive Species', fontsize=14)\n",
    "fig.subplots_adjust(top=0.92)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
